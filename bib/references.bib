@article{Agarwal2021Multimodal,
  abstract = {The paper addresses the transition from multimodal to unimodal attention in transformers using knowledge distillation techniques.},
  author = {Agarwal, D., Agrawal, T., Ferrari, L.M. and François Brémond},
  doi = {https://arxiv.org/abs/2103.15691},
  journal = {arXiv (Cornell University)},
  keywords = {multimodal, knowledge_distillation, transformers, unimodal_attention},
  number = {03},
  publisher = {Cornell University},
  volume = {2021},
  title = {From Multimodal to Unimodal Attention in Transformers using Knowledge Distillation},
  url = {https://arxiv.org/abs/2103.15691},
  year = {2021}
}

@article{Dai2022Multimodal,
  abstract = {The paper presents a method for enabling multimodal generation on CLIP via vision-language knowledge distillation.},
  author = {Dai, W., Hou, L., Shang, L., Jiang, X., Li, Q. and Fung, P.},
  doi = {https://doi.org/10.18653/v1/2022.findings-acl.187},
  journal = {Findings of the Association for Computational Linguistics: ACL 2022},
  keywords = {multimodal_generation, CLIP, vision_language, knowledge_distillation},
  number = {187},
  publisher = {Association for Computational Linguistics},
  volume = {2022},
  title = {Enabling Multimodal Generation on CLIP via Vision-Language Knowledge Distillation},
  url = {https://doi.org/10.18653/v1/2022.findings-acl.187},
  year = {2022}
}

@article{Li2023Efficient,
  abstract = {The paper proposes an efficient multimodal fusion method via interactive prompting.},
  author = {Li, Y., Quan, R., Zhu, L. and Yang, Y.},
  doi = {https://doi.org/10.1109/cvpr52729.2023.00256},
  journal = {IEEE Conference on Computer Vision and Pattern Recognition},
  keywords = {multimodal_fusion, interactive_prompting, efficient_fusion},
  number = {02},
  publisher = {IEEE},
  volume = {2023},
  title = {Efficient Multimodal Fusion via Interactive Prompting},
  url = {https://doi.org/10.1109/cvpr52729.2023.00256},
  year = {2023}
}

@article{Ma2022Data,
  abstract = {The paper discusses data augmentation techniques for audio-visual emotion recognition using an efficient multimodal conditional GAN.},
  author = {Ma, F., Li, Y., Ni, S., Huang, S.-L. and Zhang, L.},
  doi = {https://doi.org/10.3390/app12010527},
  journal = {Applied Sciences},
  keywords = {data_augmentation, audio_visual_emotion_recognition, multimodal_conditional_GAN},
  number = {527},
  publisher = {MDPI},
  volume = {12},
  series = {01},
  title = {Data Augmentation for Audio-Visual Emotion Recognition with an Efficient Multimodal Conditional GAN},
  url = {https://doi.org/10.3390/app12010527},
  year = {2022}
}

@article{Malihi2023Efficient,
  abstract = {The paper introduces efficient and controllable model compression techniques through sequential knowledge distillation and pruning.},
  author = {Malihi, L. and Heidemann, G.},
  doi = {https://doi.org/10.3390/bdcc7030154},
  journal = {Big Data and Cognitive Computing},
  keywords = {model_compression, knowledge_distillation, pruning},
  number = {154},
  publisher = {MDPI},
  volume = {7},
  series = {03},
  title = {Efficient and Controllable Model Compression through Sequential Knowledge Distillation and Pruning},
  url = {https://doi.org/10.3390/bdcc7030154},
  year = {2023}
}

@article{Middya2022Deep,
  abstract = {The paper explores deep learning-based multimodal emotion recognition using model-level fusion of audio–visual modalities.},
  author = {Middya, A.I., Nag, B. and Roy, S.},
  doi = {https://doi.org/10.1016/j.knosys.2022.108580},
  journal = {Knowledge-Based Systems},
  keywords = {deep_learning, multimodal_emotion_recognition, model_level_fusion},
  number = {108580},
  publisher = {Elsevier},
  volume = {244},
  title = {Deep Learning Based Multimodal Emotion Recognition using Model-Level Fusion of Audio–Visual Modalities},
  url = {https://doi.org/10.1016/j.knosys.2022.108580},
  year = {2022}
}

@article{Sun2023Efficient,
  abstract = {The paper proposes an efficient multimodal transformer with dual-level feature restoration for robust multimodal sentiment analysis.},
  author = {Sun, L., Lian, Z., Liu, B. and Tao, J.},
  doi = {https://doi.org/10.1109/taffc.2023.3274829},
  journal = {IEEE Transactions on Affective Computing},
  keywords = {multimodal_transformer, feature_restoration, sentiment_analysis},
  number = {01},
  publisher = {IEEE},
  volume = {2023},
  title = {Efficient Multimodal Transformer with Dual-Level Feature Restoration for Robust Multimodal Sentiment Analysis},
  url = {https://doi.org/10.1109/taffc.2023.3274829},
  year = {2023}
}

@article{Wang2020Multimodal,
  abstract = {The paper investigates multimodal learning with incomplete modalities using knowledge distillation.},
  author = {Wang, Q., Zhan, L., Thompson, P.M. and Zhou, J.},
  doi = {https://doi.org/10.1145/3394486.3403234},
  journal = {ACM Transactions on Knowledge Discovery from Data},
  keywords = {multimodal_learning, incomplete_modalities, knowledge_distillation},
  number = {03},
  publisher = {ACM},
  volume = {2020},
  title = {Multimodal Learning with Incomplete Modalities by Knowledge Distillation},
  url = {https://doi.org/10.1145/3394486.3403234},
  year = {2020}
}

@article{Wang2023VideoAdviser,
  abstract = {The paper introduces VideoAdviser, a video knowledge distillation technique for multimodal transfer learning.},
  author = {Wang, Y., Zeng, D., Wada, S. and Kurihara, S.},
  doi = {https://doi.org/10.1109/access.2023.3280187},
  journal = {IEEE Access},
  keywords = {video_knowledge_distillation, multimodal_transfer_learning},
  number = {51229},
  publisher = {IEEE},
  volume = {11},
  title = {VideoAdviser: Video Knowledge Distillation for Multimodal Transfer Learning},
  url = {https://doi.org/10.1109/access.2023.3280187},
  year = {2023}
}

@article{Xue2022Dynamic,
  abstract = {The paper presents dynamic multimodal fusion techniques for effective integration of multiple modalities.},
  author = {Xue, Z. and Marculescu, R.},
  doi = {https://doi.org/10.1109/CVPRW59228.2023.00256},
  journal = {CVPR Workshops},
  keywords = {dynamic_multimodal_fusion, multimodal_integration},
  number = {2575},
  publisher = {IEEE},
  volume = {2022},
  title = {Dynamic Multimodal Fusion},
  url = {https://doi.org/10.1109/CVPRW59228.2023.00256},
  year = {2022}
}
